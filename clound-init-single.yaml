aliases:
  dynamic_addresses_pool:
    - &pool_default !os_env POOL_DEFAULT, 10.10.0.0/16:24

  default_interface_model:
    - &interface_model !os_env INTERFACE_MODEL, e1000

template:
  devops_settings:
    env_name: !os_env ENV_NAME, single

    address_pools:
      public-pool01:
        net: *pool_default
        params:
          vlan_start: 1210
          ip_reserved:
            gateway: +1
            l2_network_device: +1
          ip_ranges:
            dhcp: [+128, -32]
            rack-01: [+2, +127]
      private-pool01:
        net: *pool_default
      storage-pool01:
        net: *pool_default
      management-pool01:
        net: *pool_default

    groups:
      - name: default
        driver:
          name: devops.driver.libvirt
          params:
            connection_string: !os_env CONNECTION_STRING, qemu:///system
            storage_pool_name: !os_env STORAGE_POOL_NAME, default
            stp: False
            hpet: False
            use_host_cpu: !os_env DRIVER_USE_HOST_CPU, true

        network_pools:
          public: public-pool01
          private: private-pool01
          storage: storage-pool01
          management: management-pool01

        l2_network_devices:
          public:
            address_pool: public-pool01
            dhcp: true
            forward:
              mode: nat

          storage:
            address_pool: storage-pool01
            dhcp: false

          management:
            address_pool: management-pool01
            dhcp: false

          private:
            address_pool: private-pool01
            dhcp: false

        nodes:
          - name: cfg01-kvm-node
            role: k8s
            params: &rack-01-node-params
              vcpu: !os_env SLAVE_NODE_CPU, 4
              memory: !os_env SLAVE_NODE_MEMORY, 10240
              boot:
                - hd
              cloud_init_volume_name: iso
              cloud_init_iface_up: enp0s3
              volumes:
                - name: system
                  capacity: !os_env NODE_VOLUME_SIZE, 10
                  source_image: /var/lib/libvirt/images/xenial-server-cloudimg-amd64-disk1.img
                  format: qcow2
                - name: iso  # Volume with name 'iso' will be used
                             # for store image with cloud-init metadata.
                  capacity: 1
                  format: raw
                  device: cdrom
                  bus: ide
                  cloudinit_meta_data: |
                    # All the data below will be stored as a string object
                    instance-id: iid-local1
                    local-hostname: {hostname}
                    network-interfaces: |
                     auto {interface_name}
                     iface {interface_name} inet static
                     address {address}
                     network {network}
                     netmask {netmask}
                     gateway {gateway}
                     dns-nameservers 8.8.8.8

                  cloudinit_user_data: |
                    #cloud-config, see http://cloudinit.readthedocs.io/en/latest/topics/examples.html
                    # All the data below will be stored as a string object

                    ssh_pwauth: True
                    users:
                     - name: ubuntu
                       sudo: ALL=(ALL) NOPASSWD:ALL
                       shell: /bin/bash
                    chpasswd:
                     list: |
                      ubuntu:ubuntu
                     expire: False

                    bootcmd:
                     # Block access to SSH while node is preparing
                     - cloud-init-per once sudo iptables -A INPUT -p tcp --dport 22 -j DROP
                     - echo 172.18.248.114 gerrit.mcp.mirantis.net >> /etc/hosts

                    write_files:
                     - path: /tmp/salt_install.sh
                       permissions: '0755'
                       content: |
                            #!/bin/bash

                            # Redirect all outputs
                            exec > >(tee -i /tmp/mk-bootstrap.log) 2>&1

                            # Add wrapper to apt-get to avoid race conditions
                            # with cron jobs running 'unattended-upgrades' script
                            aptget_wrapper() {
                                local apt_wrapper_timeout=300
                                local start_time=$(date '+%s')
                                local fin_time=$((start_time + apt_wrapper_timeout))
                                while true; do
                                    if (( "$(date '+%s')" > fin_time )); then
                                      echo "aptget_wrapper - ERROR: Timeout exceeded: ${apt_wrapper_timeout} s. Lock files are still not released. Terminating..."
                                      exit 1
                                    fi
                                    if fuser /var/lib/apt/lists/lock >/dev/null 2>&1 || fuser /var/lib/dpkg/lock >/dev/null 2>&1; then
                                      echo "aptget_wrapper - INFO: Waiting while another apt/dpkg process releases locks..."
                                      sleep 30
                                      continue
                                    else
                                      apt-get $@
                                      break
                                    fi
                                done
                            }
                            echo "Preparing base OS ..."
                            which wget >/dev/null || (aptget_wrapper update; aptget_wrapper install -y wget)
    
                            echo "deb [arch=amd64] http://apt-mk.mirantis.com/xenial nightly salt extra" > /etc/apt/sources.list.d/mcp_salt.list
                            wget -O - http://apt-mk.mirantis.com/public.gpg | apt-key add -

                            echo "deb http://repo.saltstack.com/apt/ubuntu/16.04/amd64/2016.3 xenial main" > /etc/apt/sources.list.d/saltstack.list
                            wget -O - https://repo.saltstack.com/apt/ubuntu/16.04/amd64/2016.3/SALTSTACK-GPG-KEY.pub | apt-key add -

                            aptget_wrapper clean
                            aptget_wrapper update

                            echo "Installing salt master ..."
                            aptget_wrapper install -y reclass git
                            aptget_wrapper install -y salt-master

                            [ ! -d /etc/salt/master.d ] && mkdir -p /etc/salt/master.d
                            cat << 'EOF' > /etc/salt/master.d/master.conf
                            file_roots:
                              base:
                              - /usr/share/salt-formulas/env
                            pillar_opts: False
                            open_mode: True
                            reclass: &reclass
                              storage_type: yaml_fs
                              inventory_base_uri: /srv/salt/reclass
                            ext_pillar:
                              - reclass: *reclass
                            master_tops:
                              reclass: *reclass
                            EOF

                            reclass_branch='add_galera_aio'
                            reclass_address='http://172.18.204.108/salt-models/mcp-virtual-lab'
                            #reclass_branch='master'
                            #reclass_address='https://gerrit.mcp.mirantis.net/salt-models/mcp-virtual-lab'                            

                            set -x
                            echo "Configuring reclass ..."
                            ssh-keyscan -H github.com >> ~/.ssh/known_hosts
                            if echo $reclass_branch | egrep -q "^refs"; then
                                git clone $reclass_address /srv/salt/reclass
                                cd /srv/salt/reclass
                                git fetch $reclass_address $reclass_branch && git checkout FETCH_HEAD
                                git submodule init
                                git submodule update --recursive
                                cd -
                            else
                               git clone -b $reclass_branch --recurse-submodules $reclass_address /srv/salt/reclass
                            fi
                            
                            node_hostname="$(hostname -s)"
                            node_domain='local'
                            node_name="$(hostname -s)"
                            node_cluster=''
                            cluster_name='virtual-mcp11-aio'

                            sed -i "s/192.168.10.90/$(ifconfig enp0s3 | grep 'inet addr' | awk -F' ' '{print $2}' | cut -d':' -f2)/g" /srv/salt/reclass/classes/cluster/${cluster_name}/init.yml
                            sed -i "s/172.16.10.90/$(ifconfig enp0s3 | grep 'inet addr' | awk -F' ' '{print $2}' | cut -d':' -f2)/g" /srv/salt/reclass/classes/cluster/${cluster_name}/init.yml

                            mkdir -p /srv/salt/reclass/classes/service

                            mkdir -p /srv/salt/reclass/nodes/_generated


                            echo "
                            classes:
                            - cluster.$cluster_name
                            parameters:
                              _param:
                                linux_system_codename: xenial
                                reclass_data_revision: $reclass_branch
                                reclass_data_repository: $reclass_address
                                cluster_name: $cluster_name
                                cluster_domain: $node_domain
                              linux:
                                system:
                                  name: $node_hostname
                                  domain: $node_domain
                              reclass:
                                storage:
                                  data_source:
                                    engine: local
                            " > /srv/salt/reclass/nodes/_generated/$node_hostname.$node_domain.yml

                            FORMULA_PATH=${FORMULA_PATH:-/usr/share/salt-formulas}
                            FORMULA_REPOSITORY=${FORMULA_REPOSITORY:-deb [arch=amd64] http://apt-mk.mirantis.com/xenial testing salt}
                            FORMULA_GPG=${FORMULA_GPG:-http://apt-mk.mirantis.com/public.gpg}

                            echo "Configuring salt master formulas ..."
                            which wget > /dev/null || (aptget_wrapper update; aptget_wrapper install -y wget)

                            echo "${FORMULA_REPOSITORY}" > /etc/apt/sources.list.d/mcp_salt.list
                            wget -O - "${FORMULA_GPG}" | apt-key add -

                            aptget_wrapper clean
                            aptget_wrapper update

                            export RECLASS_ROOT=${RECLASS_ROOT:-/srv/salt/reclass}
                            export CLUSTER_NAME="virtual-mcp11-aio"

                            function source_local_envs() {
                              for path in / /tmp/kitchen /srv/salt . ${RECLASS_ROOT}/classes/cluster ${RECLASS_ROOT}/classes/cluster/${CLUSTER_NAME}; do
                                for f in $(find $path -maxdepth 1 -name '*.env' 2> /dev/null); do
                                    echo "Sourcing env variables from $f"
                                    source $f
                                done
                              done
                             }
                            source_local_envs

                            [ ! -d /srv/salt/reclass/classes/service ] && mkdir -p /srv/salt/reclass/classes/service
                            
                            FORMULAS_SALT_MASTER=${FORMULAS_SALT_MASTER:- $EXTRA_FORMULAS memcached openssh ntp nginx collectd sensu heka sphinx mysql grafana libvirt rsyslog glusterfs postfix xtrabackup freeipa prometheus telegraf elasticsearch kibana rundeck devops-portal rsync docker keepalived aptly jenkins gerrit artifactory influxdb}
                            #declare -a formula_services=("linux" "reclass" "salt" "openssh" "ntp" "git" "nginx" "collectd" "sensu" "heka" "sphinx" "mysql" "grafana" "libvirt" "rsyslog" "memcached" "rabbitmq" "apache" "keystone" "glance" "nova" "neutron" "cinder" "heat" "horizon" "ironic" "tftpd-hpa" "bind" "powerdns" "designate")

                            echo -e "\nInstalling all required salt formulas\n"
                            aptget_wrapper install -y "${FORMULAS_SALT_MASTER[@]/#/salt-formula-}"

                            for formula_service in "${FORMULAS_SALT_MASTER[@]}"; do
                                echo -e "\nLink service metadata for formula ${formula_service} ...\n"
                                [ ! -L "/srv/salt/reclass/classes/service/${formula_service}" ] && \
                                ln -s ${FORMULA_PATH}/reclass/service/${formula_service} /srv/salt/reclass/classes/service/${formula_service}
                            done

                            [ ! -d /srv/salt/env ] && mkdir -p /srv/salt/env
                            [ ! -L /srv/salt/env/prd ] && ln -s ${FORMULA_PATH}/env /srv/salt/env/prd

                            [ ! -d /etc/reclass ] && mkdir /etc/reclass
                            cat << 'EOF' > /etc/reclass/reclass-config.yml
                            storage_type: yaml_fs
                            pretty_print: True
                            output: yaml
                            inventory_base_uri: /srv/salt/reclass
                            EOF

                            echo "Configuring salt minion ..."
                            [ ! -d /etc/salt/minion.d ] && mkdir -p /etc/salt/minion.d
                            echo " 
                            id: ${node_name}.${node_domain}
                            master: 127.0.0.1
                            " > /etc/salt/minion.d/minion.conf
                            aptget_wrapper install -y salt-minion

                            echo "Restarting services ..."
                            systemctl restart salt-master
                            systemctl restart salt-minion

                            echo "Showing system info and metadata ..."
                            salt-call --no-color grains.items
                            salt-call --no-color pillar.data

                            echo "Running complete state ..."
                            salt-call --no-color state.sls linux,openssh -l info
                            salt-call --no-color state.sls reclass -l info
                            salt-call --no-color state.sls salt.master.service -l info
                            salt-call --no-color state.sls salt.master
                            salt-call --no-color saltutil.sync_all
                            salt-call --no-color state.sls salt.api,salt.minion.ca -l info
                            systemctl restart salt-minion

                            set +x

                    runcmd:
                     # Prepare network connection
                     - sudo ifup {interface_name}
                     - sudo route add default gw {gateway} {interface_name}

                     # Prepare necessary packages on the node
                     - sudo apt-get update
                     - sudo apt-get upgrade -y
                     - sudo apt-get install -y git python-setuptools python-dev python-pip gcc libssl-dev libffi-dev vim software-properties-common 
                     - sudo apt-get autoremove -y
                     - sudo pip install -U setuptools pip
                     - sudo pip install 'cryptography>=1.3.2'
                     - sudo pip install 'cffi>=1.6.0'
                     - sudo pip install 'pyOpenSSL>=16.2.0'

                     - sudo /tmp/salt_install.sh

                     # Node is ready, allow SSH access
                     - sudo iptables -D INPUT -p tcp --dport 22 -j DROP

              interfaces:
                - label: enp0s3
                  l2_network_device: public
                  interface_model: *interface_model
                - label: enp0s4
                  l2_network_device: private
                  interface_model: *interface_model
                - label: enp0s5
                  l2_network_device: storage
                  interface_model: *interface_model
                - label: enp0s6
                  l2_network_device: management
                  interface_model: *interface_model
              network_config:
                enp0s3:
                  networks:
                    - public
                enp0s4:
                  networks:
                    - private
                enp0s5:
                  networks:
                    - storage
                enp0s6:
                  networks:
                    - management

